# MockBigQuery V2 - RefactorizaciÃ³n con Pydantic y Tipos Avanzados

## ðŸ†• Nuevas CaracterÃ­sticas

### âœ… Lo que tu implementaciÃ³n SÃ soporta:

- **UUID**: Identificadores Ãºnicos globales
- **JSON**: Tipo nativo de DuckDB (sin necesidad de `json.dumps/loads`)
- **DATE**: Fechas nativas
- **FOREIGN KEYS**: Integridad referencial con `REFERENCES`
- **CHECK CONSTRAINTS**: ValidaciÃ³n a nivel de base de datos
- **CASCADE**: EliminaciÃ³n en cascada

## ðŸ“ Archivos Nuevos

### `models.py`
Modelos Pydantic mejorados con:
- `DataExtractionResponse`: Modelo de dominio con validaciÃ³n
- `TradeIdea`: Modelo con foreign key y constraint de convicciÃ³n
- Modelos de Request/Response tipados
- Ejemplos en la documentaciÃ³n

### `main.py`
API FastAPI mejorada con:
- Endpoints RESTful especÃ­ficos (`/api/data-extractions`, `/api/trade-ideas`)
- PaginaciÃ³n y filtros
- Endpoints de anÃ¡lisis
- ValidaciÃ³n automÃ¡tica con Pydantic
- DocumentaciÃ³n automÃ¡tica en Swagger

### `initialization.py`
Script de inicializaciÃ³n que usa:
- UUID auto-generados
- JSON nativo
- Foreign keys para relacionar trade ideas con data extractions
- Tests de integridad referencial

## ðŸš€ ComparaciÃ³n: VersiÃ³n Anterior vs V2

### VersiÃ³n Anterior (INTEGER + TEXT)

```python
# models.py
class InsertRequest(BaseModel):
    table: str
    data: List[Dict[str, Any]]

# Tabla
CREATE TABLE data_extraction_responses (
    id INTEGER,
    tags TEXT,  # "['tag1', 'tag2']" como string
    pros TEXT   # "['pro1', 'pro2']" como string
)

# InserciÃ³n
data = {
    "tags": json.dumps(["tecnologÃ­a", "IA"]),  # Manual
    "pros": json.dumps(["Pro 1", "Pro 2"])      # Manual
}

# Lectura
tags = json.loads(row["tags"])  # Manual
```

### VersiÃ³n V2 (UUID + JSON nativo)

```python
# models.py
class DataExtractionResponse(BaseModel):
    id: UUID = Field(default_factory=uuid4)
    tags: List[str]  # Lista nativa
    pros: List[str]  # Lista nativa

# Tabla
CREATE TABLE data_extraction_responses (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tags JSON,  # Tipo nativo
    pros JSON   # Tipo nativo
)

# InserciÃ³n
data = {
    "tags": ["tecnologÃ­a", "IA"],  # Directo
    "pros": ["Pro 1", "Pro 2"]      # Directo
}

# Lectura - DuckDB devuelve listas Python directamente
tags = row["tags"]  # Ya es una lista!
```

## ðŸŽ¯ Ventajas de la RefactorizaciÃ³n

### 1. **Tipo Seguro (Type Safety)**
```python
# âŒ Antes: Sin validaciÃ³n
data = {"conviction": "alto"}  # String donde deberÃ­a ser int

# âœ… Ahora: Pydantic valida automÃ¡ticamente
idea = TradeIdea(conviction=8)  # OK
idea = TradeIdea(conviction="alto")  # ValidationError!
idea = TradeIdea(conviction=15)  # ValidationError! (debe ser 1-10)
```

### 2. **Integridad Referencial**
```python
# âœ… Foreign Key automÃ¡tico
CREATE TABLE trade_ideas (
    id UUID PRIMARY KEY,
    data_extraction_id UUID REFERENCES data_extraction_responses(id)
)

# Intentar insertar con ID inexistente = Error automÃ¡tico
# No necesitas validar manualmente en cÃ³digo
```

### 3. **Queries mÃ¡s Potentes**
```sql
-- âœ… JOIN entre tablas relacionadas
SELECT 
    ti.recommendation,
    ti.conviction,
    der.title as source_title
FROM trade_ideas ti
JOIN data_extraction_responses der ON ti.data_extraction_id = der.id
WHERE ti.conviction >= 8

-- âœ… Trabajar con JSON directamente
SELECT 
    title,
    json_array_length(tags) as num_tags,
    json_extract(pros, '$[0]') as first_pro
FROM data_extraction_responses
WHERE json_contains(tags, '"tecnologÃ­a"')
```

### 4. **UUIDs Globalmente Ãšnicos**
```python
# âœ… Genera UUID automÃ¡ticamente
INSERT INTO data_extraction_responses (title, summary, date)
VALUES ('TÃ­tulo', 'Resumen', '2024-01-01')
-- id se genera automÃ¡ticamente como UUID

# âœ… No hay colisiones entre diferentes fuentes de datos
# âœ… Distribuibles sin conflicto
# âœ… Compatibles con sistemas externos
```

### 5. **API RESTful con DocumentaciÃ³n AutomÃ¡tica**
```python
# âœ… Endpoints especÃ­ficos y tipados
@app.get("/api/trade-ideas", response_model=TradeIdeaListResponse)
def get_trade_ideas(
    min_conviction: int = Query(ge=1, le=10),
    limit: int = Query(default=10, le=100)
):
    ...

# DocumentaciÃ³n automÃ¡tica en: http://localhost:9000/docs
```

## ðŸ“Š Esquema de Base de Datos V2

```sql
-- Tabla principal: Extracciones de datos
CREATE TABLE data_extraction_responses (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title TEXT NOT NULL,
    summary TEXT NOT NULL,
    date DATE NOT NULL,
    tags JSON,
    pros JSON,
    cons JSON,
    authors JSON
);

-- Tabla relacionada: Ideas de trading
CREATE TABLE trade_ideas (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    recommendation TEXT NOT NULL,
    summary TEXT NOT NULL,
    conviction INTEGER CHECK (conviction >= 1 AND conviction <= 10),
    pros JSON,
    cons JSON,
    data_extraction_id UUID REFERENCES data_extraction_responses(id) ON DELETE CASCADE
);
```

## ðŸƒ CÃ³mo Usar

### OpciÃ³n 1: Migrar a V2 (Recomendado)

```powershell
# 1. Iniciar el servidor V2
python main.py

# 2. En otra terminal, inicializar con datos V2
python initialization.py

# 3. Probar la API
# Abrir navegador en: http://localhost:9000/docs
```

### OpciÃ³n 2: Mantener compatibilidad con ambas versiones

```powershell
# Servidor V1 en puerto 9000
python main.py

# Servidor V2 en puerto 9001
$env:PORT=9001; python main.py
```

## ðŸ“¡ Ejemplos de Uso de la API V2

### Obtener Data Extractions
```bash
GET http://localhost:9000/api/data-extractions?limit=10&offset=0&tag=tecnologÃ­a
```

### Obtener una Data Extraction especÃ­fica
```bash
GET http://localhost:9000/api/data-extractions/{uuid}
```

### Crear nueva Data Extraction
```bash
POST http://localhost:9000/api/data-extractions
Content-Type: application/json

{
  "title": "AnÃ¡lisis Q1 2025",
  "summary": "Resumen del anÃ¡lisis...",
  "date": "2025-01-15",
  "tags": ["tecnologÃ­a", "IA"],
  "pros": ["Crecimiento fuerte"],
  "cons": ["Alta volatilidad"],
  "authors": ["Juan PÃ©rez"]
}
```

### Obtener Trade Ideas con filtros
```bash
GET http://localhost:9000/api/trade-ideas?min_conviction=7&recommendation=COMPRAR
```

### Obtener Trade Ideas de una Data Extraction
```bash
GET http://localhost:9000/api/data-extractions/{uuid}/trade-ideas
```

### Analytics: DistribuciÃ³n de ConvicciÃ³n
```bash
GET http://localhost:9000/api/analytics/conviction-distribution
```

### Analytics: Top Tags
```bash
GET http://localhost:9000/api/analytics/top-tags?limit=10
```

## ðŸ”„ MigraciÃ³n desde V1 a V2

Si ya tienes datos en la versiÃ³n V1:

```python
# Script de migraciÃ³n (crear como migration.py)
import requests

old_api = "http://localhost:9000"
new_api = "http://localhost:9001"

# 1. Exportar datos de V1
old_data = requests.post(f"{old_api}/query", 
    json={"sql": "SELECT * FROM data_extraction_responses"})

# 2. Transformar e importar a V2
for row in old_data.json()["rows"]:
    # Convertir strings JSON a listas
    row["tags"] = json.loads(row["tags"])
    row["pros"] = json.loads(row["pros"])
    row["cons"] = json.loads(row["cons"])
    row["authors"] = json.loads(row["authors"])
    
    # Crear en V2
    requests.post(f"{new_api}/api/data-extractions", json=row)
```

## ðŸ§ª Tests

```powershell
# Ejecutar tests
python tests/run_all_tests.py
```

## ðŸ“š DocumentaciÃ³n Interactiva

Una vez que el servidor estÃ© corriendo:

- **Swagger UI**: http://localhost:9000/docs
- **ReDoc**: http://localhost:9000/redoc

## ðŸ’¡ Recomendaciones

1. **Usa V2 para proyectos nuevos**: Mejor tipado y mÃ¡s funcionalidades
2. **Migra gradualmente**: Puedes correr ambas versiones en paralelo
3. **Aprovecha los endpoints especÃ­ficos**: MÃ¡s semÃ¡nticos que SQL directo
4. **Usa la validaciÃ³n de Pydantic**: Previene errores en tiempo de desarrollo
5. **Explora la documentaciÃ³n automÃ¡tica**: FastAPI genera docs completos

## ðŸ› Troubleshooting

### Error: "Foreign key constraint failed"
- Verifica que el `data_extraction_id` exista antes de crear un `TradeIdea`
- Usa el endpoint GET para obtener IDs vÃ¡lidos

### Error: "Validation error"
- Revisa que los tipos coincidan con los modelos Pydantic
- `conviction` debe ser 1-10
- `date` debe estar en formato "YYYY-MM-DD"

### JSON no se deserializa correctamente
- En V2, DuckDB maneja JSON automÃ¡ticamente
- No uses `json.dumps()` al insertar
- No uses `json.loads()` al leer

## ðŸŽ“ Recursos

- [DuckDB JSON Functions](https://duckdb.org/docs/sql/functions/json)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
